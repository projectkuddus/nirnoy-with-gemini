import React, { useState, useRef, useEffect, useCallback } from 'react';
import { GoogleGenAI, Modality } from '@google/genai';
import { MOCK_DOCTORS } from '../data/mockData';

// ============ CONFIGURATION ============
const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY || '';
const hasValidApiKey = GEMINI_API_KEY && GEMINI_API_KEY.length > 10;

// ============ AUDIO HELPERS ============

// Convert Float32Array to PCM16 blob for Gemini
function float32ToPCM16Blob(float32Data: Float32Array): { data: string; mimeType: string } {
  const int16 = new Int16Array(float32Data.length);
  for (let i = 0; i < float32Data.length; i++) {
    const s = Math.max(-1, Math.min(1, float32Data[i]));
    int16[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
  }
  
  const bytes = new Uint8Array(int16.buffer);
  let binary = '';
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  
  return {
    data: btoa(binary),
    mimeType: 'audio/pcm;rate=16000',
  };
}

// Decode base64 to Uint8Array
function base64ToUint8Array(base64: string): Uint8Array {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

// Decode PCM16 to AudioBuffer
function pcm16ToAudioBuffer(
  data: Uint8Array,
  audioContext: AudioContext,
  sampleRate: number = 24000
): AudioBuffer {
  const int16Data = new Int16Array(data.buffer, data.byteOffset, data.byteLength / 2);
  const float32Data = new Float32Array(int16Data.length);
  
  for (let i = 0; i < int16Data.length; i++) {
    float32Data[i] = int16Data[i] / 32768.0;
  }
  
  const audioBuffer = audioContext.createBuffer(1, float32Data.length, sampleRate);
  audioBuffer.getChannelData(0).set(float32Data);
  
  return audioBuffer;
}

// Downsample audio to 16kHz
function downsampleBuffer(buffer: Float32Array, inputSampleRate: number, outputSampleRate: number): Float32Array {
  if (inputSampleRate === outputSampleRate) {
    return buffer;
  }
  
  const ratio = inputSampleRate / outputSampleRate;
  const newLength = Math.round(buffer.length / ratio);
  const result = new Float32Array(newLength);
  
  for (let i = 0; i < newLength; i++) {
    const index = Math.round(i * ratio);
    result[i] = buffer[Math.min(index, buffer.length - 1)];
  }
  
  return result;
}

// ============ TIME-BASED GREETING ============
function getTimeBasedGreeting(): string {
  const hour = new Date().getHours();
  if (hour >= 5 && hour < 12) return '‡¶∏‡ßÅ‡¶™‡ßç‡¶∞‡¶≠‡¶æ‡¶§';
  if (hour >= 12 && hour < 17) return '‡¶∂‡ßÅ‡¶≠ ‡¶¶‡ßÅ‡¶™‡ßÅ‡¶∞';
  if (hour >= 17 && hour < 20) return '‡¶∂‡ßÅ‡¶≠ ‡¶∏‡¶®‡ßç‡¶ß‡ßç‡¶Ø‡¶æ';
  return '‡¶∂‡ßÅ‡¶≠ ‡¶∞‡¶æ‡¶§‡ßç‡¶∞‡¶ø';
}

// ============ SYSTEM PROMPT ============
function buildSystemPrompt(agentNumber: number, isMale: boolean): string {
  const today = new Date().toLocaleDateString('bn-BD', { 
    weekday: 'long', 
    year: 'numeric', 
    month: 'long', 
    day: 'numeric' 
  });
  const greeting = getTimeBasedGreeting();
  
  // Get doctor list for context
  const doctorList = MOCK_DOCTORS.slice(0, 10).map(d => 
    `${d.name} (${d.specialties[0]}) - ${d.chambers[0]?.name}, ‡¶´‡¶ø: ‡ß≥${d.chambers[0]?.fee}`
  ).join('\n');

  const genderContext = isMale 
    ? '‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶è‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡•§ ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑‡¶∏‡ßÅ‡¶≤‡¶≠ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶¨‡¶ø‡¶®‡¶Ø‡¶º‡ßÄ ‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶®‡•§'
    : '‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶è‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡•§ ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ‡¶∏‡ßÅ‡¶≤‡¶≠ ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶π‡¶æ‡¶®‡ßÅ‡¶≠‡ßÇ‡¶§‡¶ø‡¶∂‡ßÄ‡¶≤ ‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶®‡•§';

  return `
## ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡¶∞‡¶ø‡¶ö‡¶Ø‡¶º
‡¶Ü‡¶™‡¶®‡¶ø "Nirnoy ${agentNumber}", ‡¶®‡¶ø‡¶∞‡ßç‡¶£‡¶Ø‡¶º ‡¶ï‡ßá‡¶Ø‡¶º‡¶æ‡¶∞ (Nirnoy Care) ‡¶è‡¶∞ ‡¶Ö‡¶´‡¶ø‡¶∏‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ AI ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶è‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü‡•§
${genderContext}

## ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ - ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶ï‡¶•‡¶æ (MUST DO FIRST)
‡¶ï‡¶≤ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶æ‡¶•‡ßá‡¶á ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶®‡¶ø‡¶ú‡ßá ‡¶•‡ßá‡¶ï‡ßá ‡¶¨‡¶≤‡¶§‡ßá ‡¶π‡¶¨‡ßá:
"‡¶Ü‡¶∏‡¶∏‡¶æ‡¶≤‡¶æ‡¶Æ‡ßÅ ‡¶Ü‡¶≤‡¶æ‡¶á‡¶ï‡ßÅ‡¶Æ! ${greeting}! ‡¶®‡¶ø‡¶∞‡ßç‡¶£‡¶Ø‡¶º ‡¶ï‡ßá‡¶Ø‡¶º‡¶æ‡¶∞‡ßá ‡¶∏‡ßç‡¶¨‡¶æ‡¶ó‡¶§‡¶Æ‡•§ ‡¶Ü‡¶Æ‡¶ø Nirnoy ${agentNumber}‡•§ ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø?"

‡¶è‡¶ü‡¶æ ‡¶¨‡¶≤‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶á‡¶â‡¶ú‡¶æ‡¶∞‡ßá‡¶∞ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶¨‡¶≤‡¶æ‡¶∞ ‡¶Ö‡¶™‡ßá‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§ ‡¶ï‡¶≤ ‡¶ï‡¶æ‡¶®‡ßá‡¶ï‡ßç‡¶ü ‡¶π‡¶≤‡ßá‡¶á ‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶∏‡¶æ‡¶≤‡¶æ‡¶Æ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶¨‡ßá‡¶®‡•§

## ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ - NOT ‡¶ï‡¶≤‡¶ï‡¶æ‡¶§‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ)
‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßÄ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶®‡•§ ‡¶ï‡¶≤‡¶ï‡¶æ‡¶§‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§

### ‡¶Ø‡¶æ ‡¶¨‡¶≤‡¶¨‡ßá‡¶®:
- "‡¶ú‡¶ø" (‡¶π‡ßç‡¶Ø‡¶æ‡¶Å ‡¶¨‡ßã‡¶ù‡¶æ‡¶§‡ßá)
- "‡¶Ü‡¶ö‡ßç‡¶õ‡¶æ" (‡¶¨‡ßã‡¶ù‡¶æ ‡¶ó‡ßá‡¶õ‡ßá)
- "‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá" (okay)
- "‡¶≠‡¶æ‡¶á" ‡¶¨‡¶æ "‡¶≠‡¶æ‡¶á‡¶Ø‡¶º‡¶æ" (‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
- "‡¶Ü‡¶™‡¶æ" ‡¶¨‡¶æ "‡¶¨‡ßã‡¶®" (‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)
- "‡¶ï‡ßá‡¶Æ‡¶® ‡¶Ü‡¶õ‡ßá‡¶®?"
- "‡¶¨‡¶≤‡ßá‡¶®" (tell me)
- "‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø" / "‡¶ï‡¶á‡¶∞‡¶æ ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø"
- "‡¶π‡¶Ø‡¶º‡ßá ‡¶ó‡ßá‡¶õ‡ßá" / "‡¶π‡¶á‡¶õ‡ßá"

### ‡¶Ø‡¶æ ‡¶¨‡¶≤‡¶¨‡ßá‡¶® ‡¶®‡¶æ (‡¶ï‡¶≤‡¶ï‡¶æ‡¶§‡¶æ‡¶∞ ‡¶∏‡ßç‡¶ü‡¶æ‡¶á‡¶≤):
- "‡¶¶‡¶æ‡¶¶‡¶æ" ‚ùå (use ‡¶≠‡¶æ‡¶á)
- "‡¶¶‡¶ø‡¶¶‡¶ø" ‚ùå (use ‡¶Ü‡¶™‡¶æ)
- "‡¶π‡ßç‡¶Ø‡¶æ‡¶Å ‡¶ó‡ßã" ‚ùå
- "‡¶è‡¶ï‡ßç‡¶∑‡ßÅ‡¶®‡¶ø" ‚ùå (use ‡¶è‡¶ñ‡¶®‡¶á)
- "‡¶¨‡ßá‡¶∂" ‚ùå (use ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá)

## ‡¶Ü‡¶ú‡¶ï‡ßá‡¶∞ ‡¶§‡¶æ‡¶∞‡¶ø‡¶ñ: ${today}

## ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ:
${doctorList}

## ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú:
1. ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ‡¶Ø‡¶º ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶æ
2. ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶¨‡ßÅ‡¶ï‡¶ø‡¶Ç ‡¶ï‡¶∞‡¶æ  
3. ‡¶´‡¶ø ‡¶ì ‡¶∏‡¶Æ‡¶Ø‡¶º‡¶∏‡ßÇ‡¶ö‡ßÄ ‡¶ú‡¶æ‡¶®‡¶æ‡¶®‡ßã
4. ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ

## ‡¶¨‡ßÅ‡¶ï‡¶ø‡¶Ç ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ:
1. ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®: "‡¶ï‡ßã‡¶® ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞?" ‡¶¨‡¶æ "‡¶ï‡ßÄ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ?"
2. ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶ú‡ßá‡¶∏‡ßç‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®
3. ‡¶∞‡ßã‡¶ó‡ßÄ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®
4. ‡¶Æ‡ßã‡¶¨‡¶æ‡¶á‡¶≤ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶®‡¶ø‡¶®
5. ‡¶ï‡¶®‡¶´‡¶æ‡¶∞‡ßç‡¶Æ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶ø‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶≤ ‡¶¶‡¶ø‡¶®

## ‡¶ú‡¶∞‡ßÅ‡¶∞‡¶ø ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ:
‡¶¨‡ßÅ‡¶ï‡ßá ‡¶¨‡ßç‡¶Ø‡¶•‡¶æ, ‡¶∂‡ßç‡¶¨‡¶æ‡¶∏‡¶ï‡¶∑‡ßç‡¶ü, ‡¶Ö‡¶ú‡ßç‡¶û‡¶æ‡¶® ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶¨‡¶≤‡¶≤‡ßá ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶æ‡¶•‡ßá ‡¶¨‡¶≤‡ßÅ‡¶®:
"‡¶è‡¶ü‡¶æ ‡¶á‡¶Æ‡¶æ‡¶∞‡ßç‡¶ú‡ßá‡¶®‡ßç‡¶∏‡¶ø! ‡¶è‡¶ñ‡¶®‡¶á 999 ‡¶è ‡¶ï‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶¨‡¶æ ‡¶®‡¶ø‡¶ï‡¶ü‡¶∏‡ßç‡¶• ‡¶π‡¶æ‡¶∏‡¶™‡¶æ‡¶§‡¶æ‡¶≤‡ßá ‡¶Ø‡¶æ‡¶®!"

## ‡¶ï‡¶•‡ßã‡¶™‡¶ï‡¶•‡¶® ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡¶§‡ßá:
"‡¶Ü‡¶∞ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶≤‡¶æ‡¶ó‡¶¨‡ßá?" ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡ßá‡¶∏ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶∂‡ßá‡¶∑‡ßá "‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π ‡¶π‡¶æ‡¶´‡ßá‡¶ú" ‡¶¨‡¶æ "‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶, ‡¶≠‡¶æ‡¶≤‡ßã ‡¶•‡¶æ‡¶ï‡¶¨‡ßá‡¶®" ‡¶¨‡¶≤‡ßÅ‡¶®‡•§

## ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶â‡¶§‡ßç‡¶§‡¶∞:
‡ßß-‡ß® ‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶®‡•§ ‡¶≤‡¶Æ‡ßç‡¶¨‡¶æ ‡¶≤‡¶Æ‡ßç‡¶¨‡¶æ ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§
`;
}

// ============ VOICE AGENT TYPES ============
type AgentStatus = 'idle' | 'connecting' | 'connected' | 'speaking' | 'listening' | 'error';

interface VoiceAgentState {
  activeAgent: 1 | 2 | null;
  status: AgentStatus;
  statusText: string;
  volume: number;
  error: string | null;
}

// ============ MAIN COMPONENT ============
export const HomeVoiceSection: React.FC = () => {
  const [state, setState] = useState<VoiceAgentState>({
    activeAgent: null,
    status: 'idle',
    statusText: '‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§',
    volume: 0,
    error: null,
  });

  // Refs for audio handling
  const aiClientRef = useRef<GoogleGenAI | null>(null);
  const sessionRef = useRef<any>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const audioQueueRef = useRef<AudioBufferSourceNode[]>([]);
  const nextPlayTimeRef = useRef<number>(0);
  const isConnectedRef = useRef(false);

  // Initialize AI client
  useEffect(() => {
    if (hasValidApiKey) {
      aiClientRef.current = new GoogleGenAI({ apiKey: GEMINI_API_KEY });
    }
  }, []);

  // Cleanup function
  const cleanup = useCallback(() => {
    isConnectedRef.current = false;
    
    // Stop all audio sources
    audioQueueRef.current.forEach(source => {
      try { source.stop(); } catch (e) {}
    });
    audioQueueRef.current = [];
    
    // Close session
    if (sessionRef.current) {
      try { sessionRef.current.close(); } catch (e) {}
      sessionRef.current = null;
    }
    
    // Stop media stream
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
    
    // Disconnect processor
    if (processorRef.current) {
      try { processorRef.current.disconnect(); } catch (e) {}
      processorRef.current = null;
    }
    
    // Close audio context
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      try { audioContextRef.current.close(); } catch (e) {}
      audioContextRef.current = null;
    }
    
    nextPlayTimeRef.current = 0;
    
    setState({
      activeAgent: null,
      status: 'idle',
      statusText: '‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡ßÅ‡¶§',
      volume: 0,
      error: null,
    });
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => cleanup();
  }, [cleanup]);

  // Play audio buffer
  const playAudioBuffer = useCallback((buffer: AudioBuffer, audioContext: AudioContext) => {
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(audioContext.destination);
    
    const currentTime = audioContext.currentTime;
    const startTime = Math.max(currentTime, nextPlayTimeRef.current);
    
    source.start(startTime);
    nextPlayTimeRef.current = startTime + buffer.duration;
    
    audioQueueRef.current.push(source);
    
    source.onended = () => {
      const index = audioQueueRef.current.indexOf(source);
      if (index > -1) {
        audioQueueRef.current.splice(index, 1);
      }
      
      if (audioQueueRef.current.length === 0) {
        setState(prev => {
          if (prev.status === 'speaking') {
            return { ...prev, status: 'listening', statusText: '‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶®...' };
          }
          return prev;
        });
      }
    };
  }, []);

  // Start voice session
  const startSession = async (agentNumber: 1 | 2) => {
    if (!hasValidApiKey || !aiClientRef.current) {
      setState(prev => ({
        ...prev,
        error: 'API Key ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡¶®‡¶ø‡•§',
        status: 'error',
        statusText: '‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø',
      }));
      return;
    }

    try {
      cleanup();
      
      setState({
        activeAgent: agentNumber,
        status: 'connecting',
        statusText: '‡¶ï‡¶æ‡¶®‡ßá‡¶ï‡ßç‡¶ü ‡¶π‡¶ö‡ßç‡¶õ‡ßá...',
        volume: 0,
        error: null,
      });

      // Request microphone permission
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        } 
      });
      mediaStreamRef.current = stream;

      // Create audio context for playback (24kHz output)
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      const audioContext = new AudioContextClass({ sampleRate: 24000 });
      audioContextRef.current = audioContext;
      
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }

      // Build system prompt
      // Nirnoy 1 = Male (Charon voice), Nirnoy 2 = Female (Kore voice)
      const isMale = agentNumber === 1;
      const systemPrompt = buildSystemPrompt(agentNumber, isMale);
      
      // Voice selection: Male = Charon, Female = Kore
      const voiceName = isMale ? 'Charon' : 'Kore';

      console.log(`Starting session with voice: ${voiceName}`);

      // Connect to Gemini Live API
      const session = await aiClientRef.current.live.connect({
        model: 'gemini-2.0-flash-exp',
        config: {
          responseModalities: [Modality.AUDIO],
          systemInstruction: systemPrompt,
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: {
                voiceName: voiceName,
              },
            },
          },
        },
        callbacks: {
          onopen: () => {
            console.log('Session opened');
            isConnectedRef.current = true;
            
            setState(prev => ({
              ...prev,
              status: 'connected',
              statusText: '‡¶∏‡¶Ç‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá...',
            }));

            // Send initial greeting prompt to make AI speak first
            setTimeout(() => {
              if (sessionRef.current && isConnectedRef.current) {
                console.log('Sending greeting prompt');
                sessionRef.current.sendClientContent({
                  turns: [{
                    role: 'user',
                    parts: [{ text: '‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã' }]
                  }],
                  turnComplete: true
                });
              }
            }, 500);

            // Start audio capture
            startAudioCapture(stream, audioContext);
          },
          onmessage: (message: any) => {
            // Handle audio response
            const audioPart = message.serverContent?.modelTurn?.parts?.find(
              (p: any) => p.inlineData?.mimeType?.startsWith('audio/')
            );
            
            if (audioPart?.inlineData?.data && audioContextRef.current) {
              setState(prev => ({ ...prev, status: 'speaking', statusText: '‡¶¨‡¶≤‡¶õ‡ßá...' }));
              
              try {
                const audioData = base64ToUint8Array(audioPart.inlineData.data);
                const audioBuffer = pcm16ToAudioBuffer(audioData, audioContextRef.current, 24000);
                playAudioBuffer(audioBuffer, audioContextRef.current);
              } catch (e) {
                console.error('Audio decode error:', e);
              }
            }
            
            // Handle turn complete
            if (message.serverContent?.turnComplete) {
              setState(prev => ({ 
                ...prev, 
                status: 'listening', 
                statusText: '‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶®...' 
              }));
            }

            // Handle interruption
            if (message.serverContent?.interrupted) {
              audioQueueRef.current.forEach(s => {
                try { s.stop(); } catch (e) {}
              });
              audioQueueRef.current = [];
              if (audioContextRef.current) {
                nextPlayTimeRef.current = audioContextRef.current.currentTime;
              }
            }
          },
          onclose: () => {
            console.log('Session closed');
            isConnectedRef.current = false;
            cleanup();
          },
          onerror: (error: any) => {
            console.error('Session error:', error);
            setState(prev => ({
              ...prev,
              error: '‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§',
              status: 'error',
              statusText: '‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø',
            }));
            cleanup();
          },
        },
      });

      sessionRef.current = session;

    } catch (err: any) {
      console.error('Session start error:', err);
      
      let errorMessage = '‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶è‡¶ú‡ßá‡¶®‡ßç‡¶ü ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá ‡¶®‡¶æ‡•§';
      if (err.name === 'NotAllowedError') {
        errorMessage = '‡¶Æ‡¶æ‡¶á‡¶ï‡ßç‡¶∞‡ßã‡¶´‡ßã‡¶® ‡¶™‡¶æ‡¶∞‡¶Æ‡¶ø‡¶∂‡¶® ‡¶¶‡¶ø‡¶®‡•§';
      } else if (err.name === 'NotFoundError') {
        errorMessage = '‡¶Æ‡¶æ‡¶á‡¶ï‡ßç‡¶∞‡ßã‡¶´‡ßã‡¶® ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá ‡¶®‡¶æ‡•§';
      } else if (err.message) {
        errorMessage = `‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø: ${err.message}`;
      }
      
      setState(prev => ({
        ...prev,
        error: errorMessage,
        status: 'error',
        statusText: '‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø',
      }));
      cleanup();
    }
  };

  // Start audio capture and send to session
  const startAudioCapture = (stream: MediaStream, audioContext: AudioContext) => {
    // Create a separate context for input at native sample rate
    const inputContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    const source = inputContext.createMediaStreamSource(stream);
    
    const bufferSize = 4096;
    const processor = inputContext.createScriptProcessor(bufferSize, 1, 1);
    processorRef.current = processor;
    
    let audioBuffer: Float32Array[] = [];
    const SEND_INTERVAL = 100;
    let lastSendTime = Date.now();
    
    processor.onaudioprocess = (event) => {
      if (!isConnectedRef.current || !sessionRef.current) return;
      
      const inputData = event.inputBuffer.getChannelData(0);
      
      // Calculate volume for visualization
      let sum = 0;
      for (let i = 0; i < inputData.length; i++) {
        sum += inputData[i] * inputData[i];
      }
      const rms = Math.sqrt(sum / inputData.length);
      setState(prev => ({ ...prev, volume: Math.min(1, rms * 5) }));
      
      // Downsample to 16kHz
      const downsampled = downsampleBuffer(new Float32Array(inputData), inputContext.sampleRate, 16000);
      audioBuffer.push(downsampled);
      
      // Send audio every SEND_INTERVAL ms
      const now = Date.now();
      if (now - lastSendTime >= SEND_INTERVAL && audioBuffer.length > 0) {
        const totalLength = audioBuffer.reduce((acc, buf) => acc + buf.length, 0);
        const combined = new Float32Array(totalLength);
        let offset = 0;
        for (const buf of audioBuffer) {
          combined.set(buf, offset);
          offset += buf.length;
        }
        
        const pcmBlob = float32ToPCM16Blob(combined);
        
        try {
          sessionRef.current.sendRealtimeInput({
            media: pcmBlob
          });
        } catch (e) {
          console.error('Send error:', e);
        }
        
        audioBuffer = [];
        lastSendTime = now;
      }
    };
    
    source.connect(processor);
    processor.connect(inputContext.destination);
  };

  // Render volume bars
  const renderVolumeBars = (isActive: boolean, isSpeaking: boolean) => {
    return [...Array(6)].map((_, i) => {
      let height = '15%';
      if (isActive) {
        if (isSpeaking) {
          height = `${Math.max(20, Math.random() * 100)}%`;
        } else {
          height = `${Math.max(15, state.volume * 100 * (0.5 + Math.random() * 0.5))}%`;
        }
      }
      
      return (
        <div
          key={i}
          className={`w-1 rounded-full transition-all duration-75 ${
            isActive ? (isSpeaking ? 'bg-blue-500' : 'bg-green-500') : 'bg-slate-300'
          }`}
          style={{ height }}
        />
      );
    });
  };

  // Render agent card
  const renderAgentCard = (agentNumber: 1 | 2) => {
    const isActive = state.activeAgent === agentNumber;
    const isOtherActive = state.activeAgent !== null && state.activeAgent !== agentNumber;
    const isSpeaking = isActive && state.status === 'speaking';
    const isMale = agentNumber === 1;
    
    return (
      <div className={`relative bg-white rounded-2xl p-6 border-2 transition-all duration-300 ${
        isActive 
          ? isMale ? 'border-blue-500 shadow-xl shadow-blue-500/10' : 'border-pink-500 shadow-xl shadow-pink-500/10'
          : isOtherActive 
            ? 'border-slate-100 opacity-50' 
            : isMale ? 'border-slate-200 hover:border-blue-300 hover:shadow-lg' : 'border-slate-200 hover:border-pink-300 hover:shadow-lg'
      }`}>
        {/* Active indicator */}
        {isActive && (
          <div className="absolute top-3 right-3">
            <span className="flex h-3 w-3">
              <span className="animate-ping absolute inline-flex h-full w-full rounded-full bg-green-400 opacity-75"></span>
              <span className="relative inline-flex rounded-full h-3 w-3 bg-green-500"></span>
            </span>
          </div>
        )}
        
        {/* Agent icon */}
        <div className="w-20 h-20 mx-auto mb-4 relative">
          <div className={`absolute inset-0 rounded-full ${isMale ? 'bg-blue-100' : 'bg-pink-100'}`}></div>
          <div className="absolute inset-1 bg-white rounded-full flex items-center justify-center">
            <i className={`fas ${isMale ? 'fa-user-tie' : 'fa-user'} text-3xl ${isMale ? 'text-blue-500' : 'text-pink-500'}`}></i>
          </div>
          {isSpeaking && (
            <div className={`absolute inset-0 rounded-full border-2 ${isMale ? 'border-blue-400' : 'border-pink-400'} animate-ping opacity-30`}></div>
          )}
        </div>
        
        <h3 className="text-lg font-bold text-slate-800 text-center mb-1">Nirnoy {agentNumber}</h3>
        <p className={`text-sm text-center mb-1 ${isMale ? 'text-blue-500' : 'text-pink-500'}`}>
          {isMale ? 'üéôÔ∏è ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶£‡ßç‡¶†' : 'üéôÔ∏è ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶ï‡¶£‡ßç‡¶†'}
        </p>
        <p className="text-xs text-slate-500 text-center mb-6">AI ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï</p>
        
        {isActive ? (
          <div className="space-y-4">
            {/* Volume visualization */}
            <div className="h-12 bg-slate-50 rounded-xl flex items-center justify-center gap-1 px-4">
              {renderVolumeBars(true, isSpeaking)}
            </div>
            
            {/* Status */}
            <p className={`text-center text-sm font-medium animate-pulse ${isMale ? 'text-blue-600' : 'text-pink-600'}`}>
              <i className={`${isSpeaking ? 'fas fa-volume-up' : 'fas fa-microphone'} mr-2`}></i>
              {state.statusText}
            </p>
            
            {/* End call button */}
            <button 
              onClick={cleanup}
              className="w-full py-3 bg-red-50 text-red-600 rounded-xl font-medium hover:bg-red-100 transition flex items-center justify-center gap-2"
            >
              <i className="fas fa-phone-slash"></i> ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßÅ‡¶®
            </button>
          </div>
        ) : (
          <button 
            onClick={() => startSession(agentNumber)}
            disabled={isOtherActive}
            className={`w-full py-3 rounded-xl font-medium transition flex items-center justify-center gap-2 ${
              isMale 
                ? 'bg-blue-500 text-white hover:bg-blue-600 disabled:bg-blue-300' 
                : 'bg-pink-500 text-white hover:bg-pink-600 disabled:bg-pink-300'
            } disabled:cursor-not-allowed`}
          >
            <i className="fas fa-phone"></i> ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶®
          </button>
        )}
      </div>
    );
  };

  return (
    <section className="py-20 px-4 bg-white">
      <div className="max-w-4xl mx-auto">
        {/* Header */}
        <div className="text-center mb-12">
          <div className="inline-flex items-center gap-2 px-4 py-2 bg-blue-50 rounded-full mb-4">
            <i className="fas fa-phone-volume text-blue-500"></i>
            <span className="text-sm font-bold text-blue-600">24/7 ‚Ä¢ ‡¶¨‡¶ø‡¶®‡¶æ‡¶Æ‡ßÇ‡¶≤‡ßç‡¶Ø‡ßá</span>
          </div>
          
          <h2 className="text-3xl md:text-4xl font-bold text-slate-900 mb-4">
            ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßá ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶®‡¶ø‡¶®
          </h2>
          <p className="text-slate-600 max-w-xl mx-auto">
            ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßÅ‡¶® ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ AI ‡¶è‡¶ú‡ßá‡¶®‡ßç‡¶ü‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá‡•§ ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®, ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®, ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡¶Ø‡¶º‡ßá‡¶®‡ßç‡¶ü‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶¨‡ßÅ‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®‡•§
          </p>
        </div>

        {/* Error message */}
        {state.error && (
          <div className="max-w-md mx-auto mb-8 p-4 bg-red-50 border border-red-100 rounded-xl text-red-600 text-sm flex items-center justify-center gap-2">
            <i className="fas fa-exclamation-circle"></i> {state.error}
          </div>
        )}

        {/* API Key warning */}
        {!hasValidApiKey && (
          <div className="max-w-md mx-auto mb-8 p-4 bg-amber-50 border border-amber-200 rounded-xl text-amber-700 text-sm">
            <p className="font-bold mb-1"><i className="fas fa-exclamation-triangle mr-2"></i>API Key ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®</p>
            <p className="text-xs">‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶è‡¶ú‡ßá‡¶®‡ßç‡¶ü ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá <code className="bg-amber-100 px-1 rounded">.env</code> ‡¶´‡¶æ‡¶á‡¶≤‡ßá <code className="bg-amber-100 px-1 rounded">VITE_GEMINI_API_KEY</code> ‡¶∏‡ßá‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®‡•§</p>
          </div>
        )}

        {/* Voice Agent Cards */}
        <div className="grid grid-cols-1 md:grid-cols-2 gap-6 max-w-2xl mx-auto">
          {renderAgentCard(1)}
          {renderAgentCard(2)}
        </div>

        {/* Info */}
        <div className="mt-8 text-center">
          <p className="text-sm text-slate-500 flex items-center justify-center gap-2">
            <i className="fas fa-info-circle"></i>
            Nirnoy 1 ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶£‡ßç‡¶†‡ßá, Nirnoy 2 ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶ï‡¶£‡ßç‡¶†‡ßá ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßá‡•§ ‡¶¶‡ßÅ‡¶ü‡ßã‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶è‡¶ï‡¶á‡•§
          </p>
        </div>
        
        <div className="mt-6 flex items-center justify-center gap-2 text-slate-400 text-xs">
          <i className="fas fa-lock"></i>
          <span>‡¶®‡¶ø‡¶∞‡¶æ‡¶™‡¶¶ ‡¶ì ‡¶ó‡ßã‡¶™‡¶®‡ßÄ‡¶Ø‡¶º ‚Ä¢ Powered by Gemini AI</span>
        </div>
      </div>
    </section>
  );
};

export default HomeVoiceSection;
